# Data Warehousing

# Scenario
You are a data engineer hired by an ecommerce company named SoftCart.com . The company retails download only items like E-Books, Movies, Songs etc. The company has international presence and customers from all over the world. The company would like to create a data warehouse so that it can create reports like
 * total sales per year per country
 * total sales per month per category
 * total sales per quarter per country
 * total sales per category per country
You will use your data warehousing skills to design and implement a data warehouse for the company.

## Objectives
In this assignment you will:
 * Design a Data Warehouse using the pgAdmin ERD design tool.
 * Create the schema in the Data Warehouse

# Tools / Software
 * ERD Design Tool of pgAdmin
 * PostgreSQL Database Server

# Exercise 1 - Design a Data Warehouse
The ecommerce company has provied you the sample data.
![image](https://github.com/alihsan-tsdln/ibm-data-engineering-capstone/assets/91479565/24ddc300-9e3b-4466-a0e7-362af0f5e865)
You will start your project by designing a Star Schema for the warehouse by identifying the columns for the various dimension and fact tables in the schema. Name your database as softcart
```
CREATE DATABASE softcart;
```
## Task 1 - Design the dimension table softcartDimDate
Using the ERD design tool design the table softcartDimDate. The company is looking at a granularity of a day. Which means they would like to have the ability to generate the report on yearly, monthly, daily, and weekday basis.

## Task 2 - Design the dimension table softcartDimCategory
Using the ERD design tool design the table softcartDimCategory.

## Task 3 - Design the dimension table softcartDimItem
Using the ERD design tool design the table softcartDimItem.

## Task 4 - Design the dimension table softcartDimCountry
Using the ERD design tool design the table softcartDimCountry.

## Task 5 - Design the fact table softcartFactSales
Using the ERD design tool design the table softcartFactSales.

## Task 6 - Design the relationships
Using the ERD design tool design the required relationships(one-to-one, one-to-many etc) amongst the tables.

# Exercise 2 - Create the schema
In this exercise you will create the schema of the data warehouse.
![Untitled (4)](https://github.com/alihsan-tsdln/ibm-data-engineering-capstone/assets/91479565/1d1c19c6-20d7-4b01-b262-3617152f9666)

## Task 7 - Create the schema.
Download the schema sql from ERD tool and create the schema in a database named staging.
<pre lang="sql">
-- This script was generated by a beta version of the ERD tool in pgAdmin 4.
-- Please log an issue at https://redmine.postgresql.org/projects/pgadmin4/issues/new if you find any bugs, including reproduction steps.
BEGIN;


CREATE TABLE staging."softcartDimCategory"
(
    "categoryID" integer NOT NULL,
    category text,
    "isSocialActivity" boolean,
    "isActive" boolean,
    "parentCategory" boolean,
    "categoryLevel" smallint,
    PRIMARY KEY ("categoryID")
);

CREATE TABLE staging."softcartDimCountry"
(
    "countryID" integer NOT NULL,
    "countryName" text,
    continent text,
    region text,
    "EU" boolean,
    religion text,
    "isSeaside" boolean,
    "isOceanSide" boolean,
    PRIMARY KEY ("countryID")
);

CREATE TABLE staging."softcartDimDate"
(
    date date NOT NULL,
    day smallint,
    monthnumber smallint,
    monthname text,
    year smallint,
    "isWeekday" boolean,
    CONSTRAINT "generalDateCheck" CHECK (day > 0 AND day <= 31 AND monthnumber > 0 AND monthnumber <= 12) NOT VALID
    PRIMARY KEY (date)
);

CREATE TABLE staging."softcartDimItem"
(
    item_id integer NOT NULL,
    item_name text,
    average_rate real,
    sale_count bigint,
    rotten_tomatos_rate smallint,
    metacritic_rate smallint,
    CONSTRAINT "generalItemCheck" CHECK (average_rate > 0::double precision AND average_rate <= 5::double precision AND rotten_tomatos_rate <= 100 AND rotten_tomatos_rate > 0 AND metacritic_rate > 0 AND metacritic_rate <= 100) NOT VALID
    PRIMARY KEY (item_id)
);

CREATE TABLE staging."softcartFactSales"
(
    "orderID" integer NOT NULL,
    "itemID" integer,
    "categoryID" integer,
    price money,
    "countryID" integer,
    date date,
    PRIMARY KEY ("orderID")
);

ALTER TABLE staging."softcartFactSales"
    ADD FOREIGN KEY ("categoryID")
    REFERENCES staging."softcartDimCategory" ("categoryID")
    NOT VALID;


ALTER TABLE staging."softcartFactSales"
    ADD FOREIGN KEY ("countryID")
    REFERENCES staging."softcartDimCountry" ("countryID")
    NOT VALID;


ALTER TABLE staging."softcartFactSales"
    ADD FOREIGN KEY (date)
    REFERENCES staging."softcartDimDate" (date)
    NOT VALID;


ALTER TABLE staging."softcartFactSales"
    ADD FOREIGN KEY ("itemID")
    REFERENCES staging."softcartDimItem" (item_id)
    NOT VALID;

END;
</pre>

# Data Warehouse Reporting

# Scenario
You are a data engineer hired by an ecommerce company named SoftCart.com . The company retails download only items like E-Books, Movies, Songs etc. The company has international presence and customers from all over the world. You have designed the schema for the data warehouse in the previous assignment. Data engineering is a team game. Your senior data engineer reviewed your design. Your schema design was improvised to suit the production needs of the company. In this assignment you will generate reports out of the data in the data warehouse.

# Objectives
In this assignment you will:

 * Load data into Data Warehouse
 * Write aggregation queries
 * Create MQTs

# Prepare the your environment
Before you start the assignment:

 1. Right Click on this [link](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0321EN-SkillsNetwork/datawarehousing/CREATE_SCRIPT.sql) and save this SQL file in you local system.

 2. Start PostgreSQL server

<pre lang="sh">
    psql -U postgres -W -h localhost
    # password : ${YOUR_PASSWORD}
</pre>

 3. Create a new database Test1
<pre lang="sql">
    CREATE DATABASE test1;
    # password : ${YOUR_PASSWORD}
</pre>

Connect test1 database.

<pre lang="sh">
    \c test1
</pre>

 4. Create the following tables
  * DimDate
    <pre lang="sql">
        CREATE TABLE public."DimDate"
        (
            dateid integer NOT NULL,
            date date,
            "Year" smallint,
            "Quarter" smallint,
            "QuarterName" character(2) COLLATE pg_catalog."default",
            "Month" smallint,
            "Monthname" character(9) COLLATE pg_catalog."default",
            "Day" smallint,
            "Weekday" smallint,
            "WeekdayName" character(9) COLLATE pg_catalog."default",
            CONSTRAINT "DimDate_pkey" PRIMARY KEY (dateid)
        )
        
        TABLESPACE pg_default;
        
        ALTER TABLE public."DimDate"
        OWNER to postgres;
    </pre>
    
  * DimCategory
    <pre lang="sql">
        CREATE TABLE public."DimCategory"
        (
            categoryid integer NOT NULL,
            category text COLLATE pg_catalog."default",
            CONSTRAINT "DimCategory_pkey" PRIMARY KEY (categoryid)
        )
        
        TABLESPACE pg_default;
        
        ALTER TABLE public."DimCategory"
            OWNER to postgres;
    </pre>
  * DimCountry
    <pre lang="sql">
        CREATE TABLE public."DimCountry"
        (
            countryid integer NOT NULL,
            country text COLLATE pg_catalog."default",
            CONSTRAINT "DimCountry_pkey" PRIMARY KEY (countryid)
        )
        
        TABLESPACE pg_default;
        
        ALTER TABLE public."DimCountry"
            OWNER to postgres;
    </pre>
  * FactSales
    <pre lang="sql">
        CREATE TABLE public."FactSales"
        (
            orderid integer NOT NULL,
            dateid integer,
            countryid integer,
            categoryid integer,
            amount integer,
            CONSTRAINT "FactSales_pkey" PRIMARY KEY (orderid)
            CONSTRAINT category_fk FOREIGN KEY (categoryid)
                REFERENCES public."DimCategory" (categoryid) MATCH SIMPLE
                ON UPDATE NO ACTION
                ON DELETE NO ACTION,
            CONSTRAINT countryid_fk FOREIGN KEY (countryid)
                REFERENCES public."DimCountry" (countryid) MATCH SIMPLE
                ON UPDATE NO ACTION
                ON DELETE NO ACTION,
            CONSTRAINT dateid_fk FOREIGN KEY (dateid)
                REFERENCES public."DimDate" (dateid) MATCH SIMPLE
                ON UPDATE NO ACTION
                ON DELETE NO ACTION
        )
        
        TABLESPACE pg_default;
        
        ALTER TABLE public."FactSales"
            OWNER to postgres;
    </pre>

# Loading Data
In this exercise you will load the data into the tables. You will load the data provided by the company in csv format.

## Task 1 - Load data into the dimension table DimDate
 * Download the data from [this link](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0321EN-SkillsNetwork/datawarehousing/data/DimDate.csv)
 * Load the downloaded data into DimDate table.

<pre lang="sql">
    COPY "DimDate" FROM '{$CSV_FILES_PATH}/DimDate.csv' CSV HEADER;
</pre>

## Task 2 - Load data into the dimension table DimCategory
 * Download the data from [this link](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0321EN-SkillsNetwork/datawarehousing/DimCategory.csv)
 * Load the downloaded data into DimCategory table.
 <pre lang="sql">
     COPY "DimCategory" FROM '{$CSV_FILES_PATH}/DimCategory.csv' CSV HEADER;
 </pre>

## Task 3 - Load data into the dimension table DimCountry
 * Download the data from [this link](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0321EN-SkillsNetwork/datawarehousing/DimCountry.csv)
 * Load the downloaded data into DimCountry table.
 <pre lang="sql">
    COPY "DimCountry" FROM '{$CSV_FILES_PATH}/DimCountry.csv' CSV HEADER;
 </pre>
## Task 4 - Load data into the fact table FactSales
 * Download the data from [this link](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0321EN-SkillsNetwork/datawarehousing/FactSales.csv)
 * Load this data into FactSales table.
 <pre lang="sql">
     COPY "FactSales" FROM '{$CSV_FILES_PATH}/FactSales.csv' CSV HEADER;
 </pre>
# Queries for data analytics
In this exercise you will query the data you have loaded in the previous exercise.

## Task 5 - Create a grouping sets query
Create a grouping sets query using the columns country, category, totalsales.
<pre lang="sql">
    SELECT country, category, SUM(amount) AS totalsales
    FROM "FactSales" s
    INNER JOIN "DimCountry" ON "DimCountry".countryid = s.countryid
    INNER JOIN "DimCategory" ON "DimCategory".categoryid = s.categoryid
    GROUP BY GROUPING SETS((country,category),(country),(category));
</pre>

## Task 6 - Create a rollup query
Create a rollup query using the columns year, country, and totalsales.
<pre lang="sql">
    SELECT "Year",country,SUM(amount)
    FROM "FactSales" s
    INNER JOIN "DimDate" d ON s.dateid = d.dateid
    INNER JOIN "DimCountry" dc ON s.countryid = dc.countryid 
    GROUP BY ROLLUP("Year",country);
</pre>

## Task 7 - Create a cube query
Create a cube query using the columns year, country, and average sales.
<pre lang="sql">
    SELECT "Year", country, AVG(amount) AS averagesales
    FROM "FactSales" s
    INNER JOIN "DimCountry" dc ON dc.countryid = s.countryid
    INNER JOIN "DimDate" dd ON dd.dateid = s.dateid
    GROUP BY CUBE("Year",country);
</pre>

## Task 8 - Create an MQT
Create an MQT named total_sales_per_country that has the columns country and total_sales.
<pre lang="sql">
    CREATE MATERIALIZED VIEW total_sales_per_country AS
    SELECT country, SUM(amount) as total_sales
    FROM "FactSales" s
    INNER JOIN "DimCountry" d ON s.countryid = d.countryid
    GROUP BY country
</pre>









